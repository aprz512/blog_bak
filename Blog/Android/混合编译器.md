---
title: 混合编译器
date: 2019-08-18
categories: Android
---




我们先来看一看编译器的发展历程，顺便也看一下虚拟机（与它有关系）的。

**虚拟机的变迁**：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%871.png?raw=true)



**编译器的变迁**：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%872.png?raw=true)



我们知道，Java是有自己的虚拟机的，那么Google为何放着现有的JVM不用，而是设计一个新的虚拟机？？？

在解答这问题之前，我们先来看看 Dalvik 与 JVM 的不同之处吧。

| JVM                                                          | Dalvik                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 基于堆栈的Java指令(1个字节)                                  | 基于寄存器的Dalvik指令(2、4或者6个字节)                      |
| 执行同样的功能， Java虚拟机需要更多的指令（主要是load和store指令），需要更多指令意味着要多占用CPU的时间。 | 执行同样的功能，Dalvik虚拟机需要更多的指令空间，需要更多指令空间意味着指令缓冲（i-cache）更易失效 |
| 使用class格式的类文件                                        | 使用dex（Dalvik Executable）格式的类文件                     |

从这个表格中，能看出为什么不？

一个dex文件可以包含若干个类，而一个class文件只包括一个类。由于一个dex文件可以包含若干个类，因此它可以将各个类中重复的字符串只保存一次，从而**节省了空间**，适合在内存有限的移动设备使用。提前调整好字节序和字对齐方式，使得它们更适合于本地机器，以便**提高指令执行速度**。



Dalvik虽然设计精巧，但是每次执行代码，都需要Dalvik将dex代码翻译为微处理器指令，然后交给系统处理，这样效率不高，**会让用户经常感到系统卡顿**。

为了解决这个的问题，Google在2.2版本添加了JIT编译器，当App运行时，每当遇到一个新类，JIT编译器就会对这个类进行编译，经过编译后的代码，会被优化成相当精简的原生型指令码（即native code），这样在下次执行到相同逻辑的时候，速度就会更快。

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%873.png?raw=true)

但是它也有自己的问题：

- 使用JIT也不一定加快执行速度，如果大部分代码的执行次数很少，那么编译花费的时间不一定少于执行dex的时间。所以JIT不对所有dex代码进行编译，而是只编译执行次数较多的dex为本地机器码。
- dex字节码翻译成本地机器码是发生在应用程序的运行过程中的，并且应用程序每一次重新运行的时候，都要做重做这个翻译工作，所以这个工作并不是一劳永逸，每次重新打开App，都需要进行JIT编译。
- 对执行次数频繁的dex代码进行编译和优化，减少以后使用时的翻译时间，虽然可以加快Dalvik运行速度，但是还是有弊病，那就是将dex翻译为本地机器码也要占用时间。

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%874.png?raw=true)



JIT 虽然在某种程度上弥补了 Dalvik 的不足，但是仍然浪费了不少性能，所以从 Android 5.0 开始，就摒弃了 Dalvik 虚拟机，开发出了 ART 虚拟机。



与Dalvik不同，在ART 环境中，**应用在第一次安装的时候，字节码就会预先编译成机器码，使其成为真正的本地应用**。之后打开App的时候，直接使用本地机器码运行，因此运行速度提高。

ART需要应用程序在安装时，就把程序代码转换成机器语言，所以这会消耗掉更多的存储空间，但消耗掉空间的增幅通常不会超过应用代码包大小的20%。由于有了一个转码的过程，**所以应用安装时间难免会延长**。

安装的时候，字节码会预先编译成机器码就是由 AOT 编译器执行的，对比JIT就很好理解了，一个是运行时编译，一个是安装时编译。

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%875.png?raw=true)

编译好的文件是OAT文件，该文件本质上是一个ELF文件，这里与dex(Odex)文件最大的区别是**OAT文件不再是字节码文件，而是一个可执行文件**，可以更底层的与硬件接触，运行时也省去了预编译和转译的时间。

ART + AOT 虽然解决了 Dalvik + JIT 的不足，但是它也带来了新的问题：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%876.png?raw=true)

更多需要解决的问题：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%877.png?raw=true)

有一张图，我们应该会非常熟悉，大多数人应该都碰到过这样的场景：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%878.png?raw=true)

这就是由于使用 ART + AOT 导致的。由于系统更新时，所有的应用都需要重新安装，这会导致所有的应用都需要在重新编译一遍，导致更新时间非常久。



那么，应该如何去解决这些问题呢？

首先，我们思考一个问题：**用户会使用App里面的每个功能吗？**

绝大多数用户只会使用App的部分功能。只有被用户频繁使用的功能（这个功能背后的代码）才值得被编译成本地代码。

所以，我们就可以不用预编译整个app，这样做：

在 JIT 阶段，我们可以先找出被频繁执行的代码，然后在使用预编译来优化和加速这些被频繁执行的代码，从而避免编译那些很少被用户使用的代码带来的额外消耗（储存空间，编译行为等等）。

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%879.png?raw=true)



当用户安装App的时候，不再进行预编译了，这个和KitKat的时候一样。当用户安装之后立即使用该App，仍然使用JIT编译模式来执行App，但是同时会生成一个离线的 profile 文件，这个 profile 文件会记录JIT运行时的所有 hot code（热点代码）信息。然后在未来的某个时间点，Android Framework 会基于这个 profile 文件来启动一个预编译行为，它只便于记录的热点代码。

在 JIT 阶段，它带来的好处：

- 快速安装
- 系统快速更新

在 AOT 阶段，它带来的好处：

- 快速启动，更好的运行性能
- 低消耗：CPU，储存空间，电量…

可以看到，它们 JIT 与 AOT 互相弥补了自己的不足。

获取有的人会觉得，JIT 是即时编译会比较慢，但是真的是这样吗？下面看一组数据测试：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%8710.png?raw=true)

AOT与JIT在Micro Benchmark测试中各有优劣，所以预编译还不一定快。



下面贴出几组使用混合编译后的数据：

![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%8711.png?raw=true)



![](https://github.com/aprz512/pic4aprz512/blob/master/Blog/Android-%E9%AB%98%E7%BA%A7/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E5%99%A8/%E5%9B%BE%E7%89%8712.png?raw=true)

提升还是非常明显的。

