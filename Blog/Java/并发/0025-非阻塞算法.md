---
title:  0025-非阻塞算法
index_img: /cover/26.jpg
banner_img: /cover/top.jpg
date: 2019-8-26
tags: Java-并发
categories: 并发
---

> 这篇文章，真的是很有意思，讲的都是概念性的东西，但是越读越有味道，最好多读几遍。

在并发上下文中，**非阻塞算法是一种不阻塞访问共享状态（或以其他方式协作或通信）的线程的算法**。更一般地说，如果一个线程的挂起不会导致算法中涉及的其他线程的挂起，则这个算法是非阻塞的。

为了更好的理解阻塞算法和非阻塞算法之间的区别，我会先讲解阻塞算法然后再讲解非阻塞算法。

## 阻塞算法

很多算法和并发数据结构都是阻塞的。例如，`java.util.concurrent.BlockingQueue`的不同实现都是阻塞数据结构。如果一个线程要往一个阻塞队列中插入一个元素，队列中没有足够的空间，执行插入操作的线程就会阻塞直到队列中有了可以存放插入元素的空间。

下图演示了一个阻塞算法是如何保证一个共享数据结构的行为的：

![](http://tutorials.jenkov.com/images/java-concurrency/non-blocking-algorithms-1.png)

线程 A 执行请求的操作

线程 B 会一直阻塞直到可以安全地执行操作（线程A的操作执行完）

## 非阻塞算法

Java也包含几个非阻塞数据结构。`AtomicBoolean`, `AtomicInteger`, `AtomicLong`, `AtomicReference`都是非阻塞数据结构的例子。

下图演示了一个非阻塞算法保证一个共享数据结构的行为：

![](http://tutorials.jenkov.com/images/java-concurrency/non-blocking-algorithms-2.png)

线程 B 执行请求的操作

线程 A 访问的时候，发现无法访问会直接返回，可以去做一些别的操作。



## 非阻塞算法 vs 阻塞算法

阻塞算法和非阻塞算法的主要不同在于当请求操作不能够执行时阻塞算法和非阻塞算法会怎么做。

阻塞算法会阻塞线程直到请求操作可以被执行。非阻塞算法会通知请求线程操作不能够被执行，并返回。

阻塞算法的问题：如果一个线程 T1 往一个已经满了的阻塞队列里插入一个元素，这个线程就会阻塞，直到其他线程从这个阻塞队列中取走了一些元素。如果由于某些原因，从阻塞队列中取元素的线程 T2 被阻塞在了程序的某处，那么，T1 要么一直阻塞下去，要么直到 T2 从阻塞队列中取走了一个元素。



## 并发数据结构

在一个多线程系统中，线程间通常通过一些数据结构“交流”。可以是任何的数据结构，从变量到更加高级的数据结构（队列，栈等）。为了便于多线程对数据结构的正确并发访问，必须通过某些并发算法来保护数据结构。这些并发算法让这些数据结构成为**并发数据结构**。

如果某个算法确保一个并发数据结构是阻塞的，它就被称为是一个**阻塞算法**。这个数据结构也被称为是一个**阻塞，并发数据结构**。

如果某个算法确保一个并发数据结构是非阻塞的，它就被称为是一个**非阻塞算法**。这个数据结构也被称为是一个**非阻塞，并发数据结构**。



## 单个写线程的情景

在一些场景下，你仅有唯一的一个线程在向一个共享变量写，多个线程在读这个变量。当仅有一个线程在更新一个变量，不管有多少个线程在读这个变量，都不会发生竞态条件。因此，无论时候当仅有一个线程在写一个共享变量时，你可以把这个变量声明为`volatile`。

当多个线程在一个共享变量上执行一个 read-update-write 的顺序操作时才会发生竞态条件。如果你只有一个线程在执行一个 raed-update-write 的顺序操作，其他线程都在执行读操作，将不会发生竞态条件。

下面是一个单个写线程的例子，它没有采取同步手段但任然是多线程安全的：

```java
public class SingleWriterCounter {

    private volatile long count = 0;

    /**
     * Only one thread may ever call this method,
     * or it will lead to race conditions.
     */
    public void inc() {
        this.count++;
    }


    /**
     * Many reading threads may call this method
     * @return
     */
    public long count() {
        return this.count;
    }
}
```

上面的例子中，多个线程时可以访问 SingleWriterCounter 的同一个实例的，只要只有一个线程调用 inc() 方法（不是指某一时刻一个线程，而是只有一个线程）。`count()`方法可以被多个线程调用。这样的场景将不会发生任何竞态条件。

下图，说明了线程是如何访问`count`这个volatile变量的。

![](http://tutorials.jenkov.com/images/java-concurrency/non-blocking-algorithms-3.png)



## 基于volatile变量的更高级的数据结构

使用多个`volatile`变量去创建数据结构是可以的，构建出的数据结构中每一个`volatile`变量仅被一个单个的线程写，被多个线程读。每个`volatile`变量可能被一个不同的线程写（但仅有一个）。使用像这样的数据结构多个线程可以使用这些`volatile`变量以一个非阻塞的方法彼此发送信息。

下面是一个简单的例子：

```java
public class DoubleWriterCounter {

    private volatile long countA = 0;
    private volatile long countB = 0;

    /**
     * Only one (and the same from thereon) thread may ever call this method,
     * or it will lead to race conditions.
     */
    public void incA() { this.countA++;  }


    /**
     * Only one (and the same from thereon) thread may ever call this method,
     * or it will lead to race conditions.
     */
    public void incB() { this.countB++;  }


    /**
     * Many reading threads may call this method
     */
    public long countA() { return this.countA; }


    /**
     * Many reading threads may call this method
     */
    public long countB() { return this.countB; }
}
```

只有一个线程调用 `incA()`，也只有一个线程调用 `incB()`，`countA()`和`countB()`可以被多个线程调用。这个例子实际上是两个 SingleWriterCounter 合在一起了。

下图，展示了两个线程通过类似于上面的一个数据结构进行通信的：

![](http://tutorials.jenkov.com/images/java-concurrency/non-blocking-algorithms-4.png)

## CAS 与乐观锁

如果你确实需要多个线程写同一个共享变量，使用volatile变量是不合适的。你需要独占对这个变量的访问权限（排他）。下面代码演示了Java中的同步块是如何进行排他访问的：

```java
public class SynchronizedCounter {
    long count = 0;

    public void inc() {
        synchronized(this) {
            count++;
        }
    }

    public long count() {
        synchronized(this) {
            return this.count;
        }
    }
}
```

inc() 与 count() 都有一个同步块，而同步块与 wait() - notify() 却是我们想避免的。

我们可以使用原子变量来代替这两个同步块。在这个例子中是`AtomicLong`。下面是SynchronizedCounter类的AtomicLong实现版本。

```java
import java.util.concurrent.atomic.AtomicLong;

public class AtomicCounter {
    private AtomicLong count = new AtomicLong(0);

    public void inc() {
        boolean updated = false;
        while(!updated){
            long prevCount = this.count.get();
            updated = this.count.compareAndSet(prevCount, prevCount + 1);
        }
    }

    public long count() {
        return this.count.get();
    }
}
```

这个版本是上一个版本的线程安全版本。在这一版中，我们感兴趣的是inc()方法的实现。inc()方法中不再含有一个同步块。而是被下面这些代码替代：

```java
boolean updated = false;
while(!updated){
    long prevCount = this.count.get();
    updated = this.count.compareAndSet(prevCount, prevCount + 1);
}
```

上面这些代码并不是一个原子操作。也就是说，可能会有两个不同的线程调用 inc() 方法。但是这里却没有包含竟态条件。

秘密就在于`while`循环里的第二行代码。`compareAndSet()`方法调用是一个原子操作。它用一个期望值和AtomicLong 内部的值去比较，如果这两个值相等，就把AtomicLong内部值替换为一个新值。`compareAndSet()`通常被CPU中的`compare-and-swap`指令直接支持。因此，不需要去同步，也不需要去挂起线程。

假设，这个`AtomicLong`的内部值是20。然后，两个线程去读这个值，都尝试调用`compareAndSet(20, 20 + 1)`。尽管`compareAndSet()`是一个原子操作，这个方法也会被这两个线程相继执行（**某一个时刻只有一个**）。

第一个线程会使用期望值20（这个计数器的上一个值）与AtomicLong的内部值进行比较。由于两个值是相等的，AtomicLong会更新它的内部值至21（20 + 1 ）。变量`updated`被修改为true，while循环结束。

现在，第二个线程调用`compareAndSet(20, 20 + 1)`。由于AtomicLong的内部值不再是20，这个调用将不会成功。AtomicLong的值不会再被修改为21。变量，`updated`被修改为false，线程将会再次在while循环外自旋。这段时间，它会读到值21并企图把值更新为22。如果在此期间没有其它线程调用`inc()`。第二次迭代将会成功更新AtomicLong的内部值到22。



上一部分展现的代码被称为**乐观锁**（optimistic locking）。乐观锁区别于传统的锁（有时也被称为**悲观锁**）。传统的锁会使用同步块或其他类型的锁阻塞对临界区域的访问。一个同步块或锁可能会导致线程挂起。

乐观锁允许所有的线程在不发生阻塞的情况下创建一份共享内存的拷贝。这些线程接下来可能会对它们的拷贝进行修改，并企图把它们修改后的版本写回到共享内存中。如果没有其它线程对共享内存做任何修改， CAS操作就允许线程将它的变化写回到共享内存中去。如果，另一个线程已经修改了共享内存，这个线程将不得不再次获得一个新的拷贝，在新的拷贝上做出修改，并尝试再次把它们写回到共享内存中去。

称之为“乐观锁”的原因就是：**线程会乐观的认为，其他线程在此期间（线程获得了他们想要更改的数据的副本并应用他们的更改）不会对共享内存进行更改**。当这个乐观假设成立时，这个线程仅仅在无锁的情况下完成共享内存的更新。当这个假设不成立时，线程所做的工作就会被丢弃，但仍然不使用锁。

**乐观锁适用于共享内存竞用不是非常高的情况。**如果共享内存上的内容非常多，仅仅因为更新共享内存失败，就用浪费大量的CPU周期用在拷贝和修改上。



## 不可替换的数据结构

一般的，在数据结构不是很复杂的情况下，我们可以使用 CAS 来更新一个数据结构：将数据拷贝一份，做出修改，然后将旧的替换为新的引用。

然而，一个大的数据结构可能会需要大量的内存和CPU周期来复制。这会使你的程序占用大量的内存和浪费大量的时间在拷贝操作上，导致你的程序的性能降低，特别是在这个数据结构的竞争非常高情况下。

一个线程花费在拷贝和修改这个数据结构上的时间越长，其它线程在此期间修改这个数据结构的可能性就越大。如果一个线程修改了这个数据结构，其它所有的线程都不等不再次执行 拷贝-修改 操作。这将会增大性能影响和内存浪费。

接下来的部分将会讲解一种实现非阻塞数据结构的方法，这种数据结构可以被并发修改，而不仅仅是拷贝和修改。



## 共同修改

我们可以不用每次复制原来的数据结构，而是让多个线程同时修改这个数据结构。这里的多线程同时修改并不是真正意义上的同时修改，而是说某一个线程提交自己的修改时，别的线程依然无法访问，但是如果该线程在提交自己的修改之后阻塞了，别的线程可以继续完成该线程提交的修改操作。

大致的过程如下：

- **检查另一个线程是否已经对这个数据结构提交了修改**
- **如果没有其他线程提交了修改，创建一个修改对象，然后向这个数据结构提交这次修改**
- **执行对共享数据结构的修改**
- **移除对这个修改的引用，向其它线程发送信号，告诉它们这个修改已经被执行**

第二步可以阻塞其他线程提交一个修改。因此，第二步实际的工作是作为这个数据结构的一个锁。如果一个线程已经成功提交了一个修改，其他线程就不可以再提交一个修改直到第一个修改执行完毕。

如果一个线程提交了一个修改，然后做一些其它的工作时发生阻塞，这时候，这个共享数据结构实际上是被锁住的。其它线程检测到它们不能够提交修改，这个时候我们就休要做一些特殊的操作（**为了避免一个已经提交的修改锁住共享数据结构，这个修改对象必须包含足够的信息让其他线程来完成这次修改**），我们让别的线程来帮助完成这次修改。

下面是一个蓝图：

![](http://tutorials.jenkov.com/images/java-concurrency/non-blocking-algorithms-5.png)

可以看到，上面的图中有两次检查。

**第一次检查**，是某个线程 T1 想要对数据结构提交一个修改，发现已经有别的线程 T0 提交过修改了，但是 T0 却没有完成自己提交的修改，所以 T1 需要先帮 T0 完成它提交的修改，然后再复制数据结构，创建自己的修改。

等到 T1 创建完自己的修改之后，由于不可抗力，T1 也阻塞了，这个时候 T2 又来了，所以 T2 也需要再次完成未完成的修改。**这里就是第二次检查的作用了**。



## 一个非阻塞算法的模板

在非阻塞算法方面，我（博客原作者 Jakob Jenkov ）并不是一位专家，所以，下面的模板可能错误。不要基于我提供的模板实现自己的非阻塞算法。这个模板意在告诉你一个关于非阻塞算法大致是什么样子的。如果，你想实现自己的非阻塞算法，首先学习一些实际的工业水平的非阻塞算法，然后在实践中学习更多关于非阻塞算法实现的知识。

```java
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicStampedReference;

public class NonblockingTemplate {

    public static class IntendedModification {
        public AtomicBoolean completed = new AtomicBoolean(false);
    }

    private AtomicStampedReference<IntendedModification> ongoingMod =
        new AtomicStampedReference<IntendedModification>(null, 0);

    //declare the state of the data structure here.


    public void modify() {
        while(!attemptModifyASR());
    }

    public boolean attemptModifyASR(){

        boolean modified = false;

        IntendedModification currentlyOngoingMod = ongoingMod.getReference();
        int stamp = ongoingMod.getStamp();

        if(currentlyOngoingMod == null){
            //copy data structure state - for use
            //in intended modification

            //prepare intended modification
            IntendedModification newMod = new IntendedModification();

            boolean modSubmitted =  ongoingMod.compareAndSet(null, newMod, stamp, stamp + 1);

            if(modSubmitted){

                //complete modification via a series of compare-and-swap operations.
                //note: other threads may assist in completing the compare-and-swap
                // operations, so some CAS may fail

                modified = true;
            }

        } else {
            //attempt to complete ongoing modification, so the data structure is freed up
            //to allow access from this thread.

            modified = false;
        }

        return modified;
    }
}
```

说实话，这里有个地方我有点疑问（上面代码中的 45-50行）：

```java
        } else {
            //attempt to complete ongoing modification, so the data structure is freed up
            //to allow access from this thread.

            modified = false;
        }
```

这里别的线程帮助完成提交的修改的时，应该怎么做才能不导致阻塞？

如果使用 CAS，那岂不是还是要走 copy 数据结构的套路？那就还是回到了原来的问题啊，copy 复杂的数据结构可能会导致更激烈的竞争。

或者将两个修改合并？？但是虽然这样不会 copy 数据，但是合并的操作怎么保证不阻塞？合并的时候完全使用 CAS 操作，这样就只 copy 了提交对象。



## 非阻塞算法是不容易实现的

正确的设计和实现非阻塞算法是不容易的。在尝试设计你的非阻塞算法之前，看一看是否已经有人设计了一种非阻塞算法正满足你的需求。

Java已经提供了一些非阻塞实现（比如 ConcurrentLinkedQueue），相信在Java未来的版本中会带来更多的非阻塞算法的实现。

除了Java内置非阻塞数据结构还有很多开源的非阻塞数据结构可以使用。



### 选择

非阻塞算法的第一个好处是，给了线程一个选择，当它们请求的动作不能够被执行时做些什么。不再是被阻塞在那。在这种情况下，它可以选择阻塞或自我等待，像这样把CPU的使用权让给其它的任务。

### 没有死锁

非阻塞算法的第二个好处是，一个线程的挂起不会导致其它线程挂起。这也意味着不会发生死锁。非阻塞算法任然可能产生活锁（live lock），两个线程一直请求一些动作，但一直被告知不能够被执行（由于相互影响）。

### 没有线程挂起

挂起和恢复一个线程的代价是昂贵的。

无论什么时候，一个线程阻塞，就会被挂起。由于使用非阻塞算法线程不会被挂起，这种过载就不会发生。这就意味着CPU有可能花更多时间在执行实际的业务逻辑上而不是上下文切换。

### 降低线程延迟

在这里我们提到的延迟指的是一个请求产生到线程实际的执行它之间的时间。因为在非阻塞算法中线程不会被挂起，它们就没有线程切换成本。这就意味着当一个请求执行时可以得到更快的响应，减少它们的响应延迟。

非阻塞算法通常**忙等待**直到请求动作可以被执行来降低延迟。当然，在一个非阻塞数据数据结构有着很高的线程争用的系统中，CPU可能在它们忙等待期间消耗大量的CPU周期。
